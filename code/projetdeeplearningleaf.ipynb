{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "projetdeeplearningleaf.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pany3BcF5E8s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.init as init\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "from torchvision.transforms import ToTensor, ToPILImage, Normalize, Compose\n",
        "import tarfile\n",
        "\n",
        "import pandas as pd\n",
        "from zipfile import ZipFile\n",
        "import io\n",
        "import cv2 \n",
        "import os\n",
        "from google.colab import files\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from pylab import *\n",
        "\n",
        "from PIL import Image\n",
        "from io import BytesIO"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iff2l5CX_4h4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def count_parameters(model):\n",
        "    #for parameter in model.parameters():\n",
        "    #    print(parameter)\n",
        "    #print ('nb of trainable parameters')\n",
        "    return (sum([p.numel() for p in model.parameters() if p.requires_grad]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVKV6nbG63e-",
        "colab_type": "code",
        "outputId": "235e65e1-9450-458c-bb11-676946544853",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "file_name = \"Output_seuillage.zip\"\n",
        "path_csv = '/content/Output_seuillage/small_training_dataset.csv'\n",
        "\n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "  zip.extractall();\n",
        "  print('done')\n",
        "csv = pd.read_csv(path_csv)\n",
        "csv.columns = [c.replace(' ', '_') for c in csv.columns]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61usFH5dB7yk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "984e3ffa-39f1-47c7-9653-57f70b96b225"
      },
      "source": [
        "print(csv.index.values)\n",
        "print(csv.ID.values)\n",
        "test = {}\n",
        "i = 0\n",
        "for row in csv.species.values:\n",
        "  if row not in test:\n",
        "    test[row] = i\n",
        "    i = i + 1\n",
        "print(test)\n",
        "print(test.get('Populus nigra'))\n",
        "print(list(test.keys())[list(test.values()).index(1)]) \n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 2 3 4 5 6 7 8]\n",
            "[12257 21288 22548  2725 32095  3345 36038 36244  4939]\n",
            "{'Syringa vulgaris': 0, 'Populus nigra': 1}\n",
            "1\n",
            "Populus nigra\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJTcxCjk7jvH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ImageDataset(Dataset):\n",
        "  def __init__(self, txt_path='/content/Output_seuillage/small_training_dataset.csv'\n",
        ", img_dir='/content/Output_seuillage/', transform=None, test=False):\n",
        "     # initialize variables such is path to csv file and images and transforms\n",
        "    df = pd.read_csv(txt_path)\n",
        "   \n",
        "    categories = {}\n",
        "    i = 0\n",
        "    for row in df.species.values:\n",
        "      if row not in categories:\n",
        "        categories[row] = i\n",
        "        i = i + 1\n",
        "    self.categories = categories\n",
        "    self.img_names = df.ID.values\n",
        "    self.format_img = '.jpg'\n",
        "    self.species = df.species.values\n",
        "    self.txt_path = txt_path\n",
        "    self.img_dir = img_dir\n",
        "    self.transform = transform\n",
        "    self.to_tensor = ToTensor()\n",
        "    self.to_pil = ToPILImage()\n",
        "\n",
        "    self.get_image_selector = True if img_dir.__contains__('tar') else False\n",
        "    self.tf = tarfile.open(self.img_dir) if self.get_image_selector else None\n",
        "    self.transform_gt = transform if test else Compose(self.transform.transforms[:-1])  # omit noise of ground truth\n",
        "    \n",
        "    print(\"dataset initialise\")\n",
        "  def __len__(self):\n",
        "      # here you just need to return a single integer number as the length of your dataset, in your \n",
        "      #  case, number of images in your train folder or lines in csv file\n",
        "    return len(self.img_names)\n",
        "      #return 1;\n",
        "  def get_image_from_folder(self, name):\n",
        "        \"\"\"\n",
        "        gets a image by a name gathered from file list text file\n",
        "        :param name: name of targeted image\n",
        "        :return: a PIL image\n",
        "        \"\"\"\n",
        "        image_name = os.path.join(self.img_dir, str(name))\n",
        "        image_name =image_name + str(self.format_img)\n",
        "        image = Image.open(image_name)\n",
        "        #image = plt.imread(image_name)\n",
        "        \n",
        "        trans1 = transforms.ToTensor()\n",
        "      \n",
        "        return trans1(image)\n",
        "  def getTarget(self, index):\n",
        "    return self.categories.get(self.species[index])\n",
        "  def getNameSpecies(self, idDictionary):\n",
        "    return list(test.keys())[list(test.values()).index(idDictionary)]\n",
        "  def show(self, index):\n",
        "    trans = transforms.ToPILImage()\n",
        "    img = self.get_image_from_folder(self.img_names[index])\n",
        "    plt.imshow(trans(img))\n",
        "  def __getitem__(self, index): \n",
        "    if index == (self.__len__() - 1) and self.get_image_selector:  # close tarfile opened in __init__\n",
        "              self.tf.close()\n",
        "    \n",
        "    print(self.img_names[index])\n",
        "    img = self.get_image_from_folder(self.img_names[index])\n",
        "    #spc = self.species[index]\n",
        "    spc = self.getTarget(index)\n",
        "    \n",
        "    sample = (img, spc)\n",
        "    \n",
        "\n",
        "    return sample\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9v882IILGngZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "outputId": "bd908536-0cd8-447b-cd33-026b17990987"
      },
      "source": [
        "custom_transforms = Compose([ ToTensor()])\n",
        "train_dataset = ImageDataset(txt_path='/content/Output_seuillage/small_training_dataset.csv',\n",
        "                              img_dir='/content/Output_seuillage/',\n",
        "                              transform= custom_transforms,\n",
        "                              test=False)\n",
        "\n",
        "print('Reduced Dataset')\n",
        "print('Number of samples: ', len(train_dataset))\n",
        "img, target = train_dataset[3] # load 4th sample\n",
        "print(img.min())\n",
        "print(img.max())\n",
        "\n",
        "\n",
        "print(\"Image Size: \", img.size())\n",
        "print(target)\n",
        "train_dataset.show(3)\n",
        "\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dataset initialise\n",
            "Reduced Dataset\n",
            "Number of samples:  9\n",
            "2725\n",
            "tensor(0.)\n",
            "tensor(1.)\n",
            "Image Size:  torch.Size([1, 28, 28])\n",
            "0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXkXcKo4xoGd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
        "#structure de pytorch facilitant l acces a une base de donnée\n",
        "testloader  = torch.utils.data.DataLoader(train_dataset,  batch_size=64, shuffle=True, num_workers=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9FdgQXCyDb7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MLPNet(nn.Module):\n",
        "    def __init__(self,s):\n",
        "        super(MLPNet, self).__init__()\n",
        "        self.name = 'mlp'\n",
        "        self.s    = s\n",
        "        self.fc1  = nn.Linear(int(np.prod(s)), 10)\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, int(np.prod(self.s)))  # flatten images\n",
        "        x = self.fc1(x)\n",
        "        return (x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNBbh58C0gmf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_params(net):\n",
        "    '''Init layer parameters.'''\n",
        "    for m in net.modules():\n",
        "        #print(m)\n",
        "        if isinstance(m, nn.Conv2d):\n",
        "            init.kaiming_normal_(m.weight, mode='fan_out')\n",
        "            #if m.bias:\n",
        "            init.constant_(m.bias, 0)\n",
        "        elif isinstance(m, nn.BatchNorm2d):\n",
        "            init.constant_(m.weight, 1)\n",
        "            init.constant_(m.bias, 0)\n",
        "        elif isinstance(m, nn.Linear):\n",
        "            init.normal_(m.weight, std=1e-3)\n",
        "            #if m.bias:\n",
        "            init.constant_(m.bias, 0) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGSq7fWEyQbM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7ab42f6b-52e5-49b8-b901-50da0beac349"
      },
      "source": [
        "cuda_available = torch.cuda.is_available()\n",
        "print(cuda_available)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHuR-nseyRLy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dlossesTR    = {}\n",
        "dlossesTRAll = {}\n",
        "dlossesTE    = {}\n",
        "didxEpoch    = {}\n",
        "dbestAcc     = {}\n",
        "dnbParam     = {}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3EgiFE5yUpD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "4984c989-4fa0-47e2-fbd9-ddc38f065f70"
      },
      "source": [
        "s = train_dataset[0][0].size()\n",
        "net = MLPNet(s)\n",
        "\n",
        "\n",
        "\n",
        "# randon init of the network weight\n",
        "init_params(net)\n",
        "\n",
        "\n",
        "lr0 = 1e-3\n",
        "#MLPnet lr0 a 1e-3\n",
        "#learning rate si petit pas de convergence si trop grand on part dans les choux\n",
        "\n",
        "test_name = net.name + '_lr0_' + \"{:.1e}\".format(lr0)\n",
        "\n",
        "print(test_name)\n",
        "\n",
        "if cuda_available:\n",
        "    net = net.cuda()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=lr0)#algo d'optimisation\n",
        "criterion = nn.CrossEntropyLoss()#fct coût\n",
        "\n",
        "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
        "lr_step  = 5\n",
        "lr_gamma = 0.1\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12257\n",
            "mlp_lr0_1.0e-03\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLxm0TH60ya6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e35dd6d0-f51e-40d7-b185-11d025c27e88"
      },
      "source": [
        "# to store losses for all epochs / iterations\n",
        "lossesTR    = []\n",
        "lossesTRAll = []\n",
        "lossesTE    = []\n",
        "idxEpoch    = [0]\n",
        "bestAcc     = 0\n",
        "\n",
        "# iterate for each epoch (1 epoch 1 passage sur la base de donnée)\n",
        "#a chaque ite on met les gradients a 0 et faire un passage dans le reseau\n",
        "for epoch in range(20):\n",
        "    # potentially decrease lr \n",
        "    # scheduler.step()\n",
        "    lr = lr0 * lr_gamma**int(epoch/lr_step)\n",
        "    optimizer.lr = lr\n",
        "    print (lr)\n",
        "    \n",
        "    losses = []\n",
        "    # Train : 1 epoch <-> loop once one the entire training dataset\n",
        "    start = time.time()\n",
        "    '''\n",
        "    for i in range(0, len(train_dataset)):\n",
        "      inputs = train_dataset[i]['X']\n",
        "    '''\n",
        "    for batch_idx, (inputs,targets) in enumerate(trainloader):\n",
        "        if cuda_available:\n",
        "            inputs, targets = inputs.cuda(), targets.cuda()\n",
        "        # clear gradient    \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # convert input to Variable\n",
        "        #inputs, targets = Variable(inputs), Variable(targets)\n",
        "        \n",
        "        # compute the output of the network for the given inputs\n",
        "        outputs = net(inputs)\n",
        "        \n",
        "        # compute the loss function\n",
        "        loss = criterion(outputs, targets)\n",
        "        \n",
        "        # compute the gradient w.r. to all weights \n",
        "        loss.backward()\n",
        "        \n",
        "        # one update of the parameter update\n",
        "        optimizer.step()\n",
        "        \n",
        "        # store loss of the current iterate\n",
        "        losses.append(loss.data.item())\n",
        "        lossesTRAll.append(loss.data.item())\n",
        "\n",
        "        end = time.time()\n",
        "    # meanlosses = torch.mean(torch.stack(losses)) \n",
        "    lossesTR.append(np.mean(losses))\n",
        "    idxEpoch.append(idxEpoch[-1] + len(losses))\n",
        "    print('Epoch : %d Train Loss : %.3f         time: %.3f' % (epoch, np.mean(losses),end-start))\n",
        "    \n",
        "    # Evaluate the current network on the validation dataset\n",
        "    net.eval()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    losses = []\n",
        "    start = time.time()\n",
        "    #validation\n",
        "    for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "        if cuda_available:\n",
        "            inputs, targets = inputs.cuda(), targets.cuda()\n",
        "\n",
        "        #inputs, targets = Variable(inputs, volatile=True), Variable(targets, volatile=True)\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        losses.append(loss.data.item())\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets.data).cpu().sum()\n",
        "    end = time.time()\n",
        "    lossesTE.append(np.mean(losses))\n",
        "\n",
        "    bestAcc = max(bestAcc,100.*correct/total)\n",
        "    print('Epoch : %d Test Loss  : %.3f        Test Acc %.3f       time: %.3f' % (epoch, np.mean(losses),100.*correct/total,end-start))\n",
        "    print('--------------------------------------------------------------')\n",
        "    net.train()\n",
        "print('done')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.001\n",
            "32095\n",
            "2725\n",
            "3345\n",
            "36244\n",
            "22548\n",
            "4939\n",
            "12257\n",
            "36038\n",
            "21288\n",
            "Epoch : 0 Train Loss : 2.299         time: 0.134\n",
            "36244\n",
            "36038\n",
            "32095\n",
            "12257\n",
            "4939\n",
            "3345\n",
            "2725\n",
            "21288\n",
            "22548\n",
            "Epoch : 0 Test Loss  : 1.954        Test Acc 88.889       time: 0.136\n",
            "--------------------------------------------------------------\n",
            "0.001\n",
            "32095\n",
            "22548\n",
            "4939\n",
            "3345\n",
            "12257\n",
            "36038\n",
            "36244\n",
            "2725\n",
            "21288\n",
            "Epoch : 1 Train Loss : 1.954         time: 0.092\n",
            "32095\n",
            "4939\n",
            "3345\n",
            "12257\n",
            "36038\n",
            "22548\n",
            "36244\n",
            "21288\n",
            "2725\n",
            "Epoch : 1 Test Loss  : 1.646        Test Acc 88.889       time: 0.133\n",
            "--------------------------------------------------------------\n",
            "0.001\n",
            "32095\n",
            "36038\n",
            "2725\n",
            "3345\n",
            "12257\n",
            "4939\n",
            "21288\n",
            "36244\n",
            "22548\n",
            "Epoch : 2 Train Loss : 1.646         time: 0.091\n",
            "36244\n",
            "4939\n",
            "32095\n",
            "2725\n",
            "12257\n",
            "3345\n",
            "21288\n",
            "22548\n",
            "36038\n",
            "Epoch : 2 Test Loss  : 1.382        Test Acc 88.889       time: 0.119\n",
            "--------------------------------------------------------------\n",
            "0.001\n",
            "3345\n",
            "32095\n",
            "22548\n",
            "21288\n",
            "36038\n",
            "4939\n",
            "36244\n",
            "12257\n",
            "2725\n",
            "Epoch : 3 Train Loss : 1.382         time: 0.089\n",
            "32095\n",
            "3345\n",
            "22548\n",
            "21288\n",
            "4939\n",
            "36038\n",
            "12257\n",
            "36244\n",
            "2725\n",
            "Epoch : 3 Test Loss  : 1.165        Test Acc 88.889       time: 0.129\n",
            "--------------------------------------------------------------\n",
            "0.001\n",
            "36038\n",
            "21288\n",
            "3345\n",
            "22548\n",
            "4939\n",
            "32095\n",
            "2725\n",
            "12257\n",
            "36244\n",
            "Epoch : 4 Train Loss : 1.165         time: 0.087\n",
            "12257\n",
            "32095\n",
            "36244\n",
            "3345\n",
            "2725\n",
            "4939\n",
            "36038\n",
            "21288\n",
            "22548\n",
            "Epoch : 4 Test Loss  : 0.993        Test Acc 88.889       time: 0.130\n",
            "--------------------------------------------------------------\n",
            "0.0001\n",
            "12257\n",
            "3345\n",
            "22548\n",
            "2725\n",
            "4939\n",
            "36038\n",
            "36244\n",
            "21288\n",
            "32095\n",
            "Epoch : 5 Train Loss : 0.993         time: 0.090\n",
            "21288\n",
            "4939\n",
            "12257\n",
            "32095\n",
            "36244\n",
            "36038\n",
            "22548\n",
            "3345\n",
            "2725\n",
            "Epoch : 5 Test Loss  : 0.860        Test Acc 100.000       time: 0.128\n",
            "--------------------------------------------------------------\n",
            "0.0001\n",
            "3345\n",
            "2725\n",
            "4939\n",
            "22548\n",
            "21288\n",
            "36244\n",
            "32095\n",
            "36038\n",
            "12257\n",
            "Epoch : 6 Train Loss : 0.860         time: 0.093\n",
            "32095\n",
            "21288\n",
            "22548\n",
            "3345\n",
            "36244\n",
            "12257\n",
            "36038\n",
            "4939\n",
            "2725\n",
            "Epoch : 6 Test Loss  : 0.755        Test Acc 100.000       time: 0.134\n",
            "--------------------------------------------------------------\n",
            "0.0001\n",
            "3345\n",
            "32095\n",
            "21288\n",
            "4939\n",
            "2725\n",
            "36038\n",
            "12257\n",
            "36244\n",
            "22548\n",
            "Epoch : 7 Train Loss : 0.755         time: 0.088\n",
            "21288\n",
            "2725\n",
            "36244\n",
            "4939\n",
            "3345\n",
            "32095\n",
            "12257\n",
            "36038\n",
            "22548\n",
            "Epoch : 7 Test Loss  : 0.673        Test Acc 100.000       time: 0.124\n",
            "--------------------------------------------------------------\n",
            "0.0001\n",
            "21288\n",
            "32095\n",
            "4939\n",
            "12257\n",
            "36244\n",
            "3345\n",
            "2725\n",
            "36038\n",
            "22548\n",
            "Epoch : 8 Train Loss : 0.673         time: 0.094\n",
            "4939\n",
            "2725\n",
            "12257\n",
            "22548\n",
            "21288\n",
            "32095\n",
            "3345\n",
            "36244\n",
            "36038\n",
            "Epoch : 8 Test Loss  : 0.606        Test Acc 100.000       time: 0.130\n",
            "--------------------------------------------------------------\n",
            "0.0001\n",
            "3345\n",
            "2725\n",
            "36244\n",
            "4939\n",
            "32095\n",
            "21288\n",
            "36038\n",
            "22548\n",
            "12257\n",
            "Epoch : 9 Train Loss : 0.606         time: 0.091\n",
            "3345\n",
            "21288\n",
            "22548\n",
            "36244\n",
            "32095\n",
            "4939\n",
            "2725\n",
            "36038\n",
            "12257\n",
            "Epoch : 9 Test Loss  : 0.550        Test Acc 100.000       time: 0.125\n",
            "--------------------------------------------------------------\n",
            "1.0000000000000003e-05\n",
            "21288\n",
            "4939\n",
            "12257\n",
            "36038\n",
            "2725\n",
            "32095\n",
            "36244\n",
            "22548\n",
            "3345\n",
            "Epoch : 10 Train Loss : 0.550         time: 0.093\n",
            "4939\n",
            "32095\n",
            "22548\n",
            "21288\n",
            "12257\n",
            "36038\n",
            "2725\n",
            "3345\n",
            "36244\n",
            "Epoch : 10 Test Loss  : 0.503        Test Acc 100.000       time: 0.127\n",
            "--------------------------------------------------------------\n",
            "1.0000000000000003e-05\n",
            "36244\n",
            "32095\n",
            "12257\n",
            "36038\n",
            "4939\n",
            "3345\n",
            "22548\n",
            "21288\n",
            "2725\n",
            "Epoch : 11 Train Loss : 0.503         time: 0.093\n",
            "22548\n",
            "3345\n",
            "32095\n",
            "4939\n",
            "12257\n",
            "36038\n",
            "21288\n",
            "2725\n",
            "36244\n",
            "Epoch : 11 Test Loss  : 0.461        Test Acc 100.000       time: 0.124\n",
            "--------------------------------------------------------------\n",
            "1.0000000000000003e-05\n",
            "2725\n",
            "36038\n",
            "32095\n",
            "36244\n",
            "3345\n",
            "22548\n",
            "21288\n",
            "12257\n",
            "4939\n",
            "Epoch : 12 Train Loss : 0.461         time: 0.086\n",
            "22548\n",
            "36244\n",
            "3345\n",
            "21288\n",
            "12257\n",
            "32095\n",
            "2725\n",
            "4939\n",
            "36038\n",
            "Epoch : 12 Test Loss  : 0.424        Test Acc 100.000       time: 0.120\n",
            "--------------------------------------------------------------\n",
            "1.0000000000000003e-05\n",
            "36244\n",
            "2725\n",
            "32095\n",
            "4939\n",
            "12257\n",
            "3345\n",
            "36038\n",
            "21288\n",
            "22548\n",
            "Epoch : 13 Train Loss : 0.424         time: 0.091\n",
            "36244\n",
            "12257\n",
            "2725\n",
            "32095\n",
            "22548\n",
            "4939\n",
            "36038\n",
            "21288\n",
            "3345\n",
            "Epoch : 13 Test Loss  : 0.390        Test Acc 100.000       time: 0.120\n",
            "--------------------------------------------------------------\n",
            "1.0000000000000003e-05\n",
            "22548\n",
            "2725\n",
            "36244\n",
            "36038\n",
            "12257\n",
            "4939\n",
            "32095\n",
            "21288\n",
            "3345\n",
            "Epoch : 14 Train Loss : 0.390         time: 0.098\n",
            "2725\n",
            "32095\n",
            "4939\n",
            "22548\n",
            "36038\n",
            "12257\n",
            "21288\n",
            "36244\n",
            "3345\n",
            "Epoch : 14 Test Loss  : 0.360        Test Acc 100.000       time: 0.131\n",
            "--------------------------------------------------------------\n",
            "1.0000000000000002e-06\n",
            "2725\n",
            "3345\n",
            "22548\n",
            "32095\n",
            "4939\n",
            "36038\n",
            "36244\n",
            "21288\n",
            "12257\n",
            "Epoch : 15 Train Loss : 0.360         time: 0.093\n",
            "12257\n",
            "22548\n",
            "3345\n",
            "36244\n",
            "32095\n",
            "4939\n",
            "36038\n",
            "21288\n",
            "2725\n",
            "Epoch : 15 Test Loss  : 0.333        Test Acc 100.000       time: 0.126\n",
            "--------------------------------------------------------------\n",
            "1.0000000000000002e-06\n",
            "21288\n",
            "4939\n",
            "36038\n",
            "22548\n",
            "32095\n",
            "12257\n",
            "3345\n",
            "36244\n",
            "2725\n",
            "Epoch : 16 Train Loss : 0.333         time: 0.092\n",
            "12257\n",
            "21288\n",
            "22548\n",
            "2725\n",
            "4939\n",
            "36038\n",
            "3345\n",
            "32095\n",
            "36244\n",
            "Epoch : 16 Test Loss  : 0.309        Test Acc 100.000       time: 0.126\n",
            "--------------------------------------------------------------\n",
            "1.0000000000000002e-06\n",
            "36038\n",
            "21288\n",
            "36244\n",
            "22548\n",
            "3345\n",
            "32095\n",
            "12257\n",
            "4939\n",
            "2725\n",
            "Epoch : 17 Train Loss : 0.309         time: 0.099\n",
            "32095\n",
            "36038\n",
            "21288\n",
            "36244\n",
            "2725\n",
            "4939\n",
            "22548\n",
            "3345\n",
            "12257\n",
            "Epoch : 17 Test Loss  : 0.287        Test Acc 100.000       time: 0.127\n",
            "--------------------------------------------------------------\n",
            "1.0000000000000002e-06\n",
            "32095\n",
            "4939\n",
            "36244\n",
            "2725\n",
            "22548\n",
            "36038\n",
            "3345\n",
            "12257\n",
            "21288\n",
            "Epoch : 18 Train Loss : 0.287         time: 0.097\n",
            "12257\n",
            "21288\n",
            "36038\n",
            "36244\n",
            "32095\n",
            "4939\n",
            "22548\n",
            "3345\n",
            "2725\n",
            "Epoch : 18 Test Loss  : 0.267        Test Acc 100.000       time: 0.122\n",
            "--------------------------------------------------------------\n",
            "1.0000000000000002e-06\n",
            "32095\n",
            "4939\n",
            "12257\n",
            "21288\n",
            "36038\n",
            "36244\n",
            "2725\n",
            "3345\n",
            "22548\n",
            "Epoch : 19 Train Loss : 0.267         time: 0.086\n",
            "3345\n",
            "2725\n",
            "4939\n",
            "21288\n",
            "32095\n",
            "36038\n",
            "12257\n",
            "22548\n",
            "36244\n",
            "Epoch : 19 Test Loss  : 0.250        Test Acc 100.000       time: 0.117\n",
            "--------------------------------------------------------------\n",
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APUDV__1_kRY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "outputId": "5bf0e8c5-318d-4e43-ea9c-717307e2c535"
      },
      "source": [
        "lossesTR\n",
        "dlossesTR[test_name]    = lossesTR\n",
        "dlossesTRAll[test_name] = lossesTRAll\n",
        "dlossesTE[test_name]    = lossesTE\n",
        "didxEpoch[test_name]    = idxEpoch\n",
        "dbestAcc[test_name]     = bestAcc\n",
        "dnbParam[test_name]     = count_parameters(net)\n",
        "print('test')\n",
        "#for n in ['convnet', 'CNN2']:\n",
        "for n in [ test_name ]: # ajouter dans cette liste le nom des reseaux que vous tester \n",
        "    if n in dlossesTR:\n",
        "        print ('----------------------------------------------------------------------------')\n",
        "        print ('----------------------------------------------------------------------------')\n",
        "        print ('----------------------------------------------------------------------------')\n",
        "        print (n)\n",
        "        print ('best accuracy      : '+str(dbestAcc[n].item()))\n",
        "        print ('best loss on train : '+str(np.min(dlossesTR[n])) + ' idx '+str(np.argmin(dlossesTR[n])))\n",
        "        print ('best loss on test  : '+str(np.min(dlossesTE[n])) + ' idx '+str(np.argmin(dlossesTE[n])))\n",
        "        print ('n param            : '+str(dnbParam[n]))\n",
        "\n",
        "        # evenly sampled time at 200ms intervals\n",
        "        t = np.arange(0, len(dlossesTRAll[n]))\n",
        "        print('test')\n",
        "        plt.plot(t, dlossesTRAll[n], 'b', didxEpoch[n][1:], dlossesTR[n], 'ro', didxEpoch[n][1:], dlossesTE[n], 'gs')\n",
        "        plt.title(n)\n",
        "        plt.show()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test\n",
            "----------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------\n",
            "----------------------------------------------------------------------------\n",
            "mlp_lr0_1.0e-03\n",
            "best accuracy      : 100.0\n",
            "best loss on train : 0.26728612184524536 idx 19\n",
            "best loss on test  : 0.2498171627521515 idx 19\n",
            "n param            : 7850\n",
            "test\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n6CIiRUKBLiJSJP4/onO5hXcj3dUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}